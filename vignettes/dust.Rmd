---
title: "dust: Introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{dust: Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5)
lang_output <- function(x, lang) {
  cat(c(sprintf("```%s", lang), x, "```"), sep = "\n")
}
cc_output <- function(x) lang_output(x, "cc")
r_output <- function(x) lang_output(x, "r")
plain_output <- function(x) lang_output(x, "plain")
```

Stochastic models can be used in statistical inference via methods such as [particle filtering](https://en.wikipedia.org/wiki/Particle_filter) but doing so requires that the models can be run over and over again very quickly. While R has excellent support for sampling from distributions, it is not necessarily well suited for this sort of problem because R is single threaded, so we are forced to evaluate realisations of the stochastic process in series (one after another) rather than in parallel.

The `dust` package provides tools to help write stochastic models that can be evaluated in parallel. It does not directly provide statistical methods; see the [mcstate](https://mrc-ide.github.io/mcstate/) package for that. Instead, it focuses on providing:

* a fast random number generator that can be evaluated in parallel (see `vignette("rng")` for details)
* a way of wrapping a user-provided model, itself written as a C++ class
* a lightweight interface that drives this model from R
* a set of useful primitives for developing sequential Monte Carlo methods.

## A simple example - random walk

Consider a unbiased random walk; at each time step we move our position with a draw from a normal distribution with mean 0 and some standard deviation. We consider a single individual moving but will eventually simulate a family of these individuals, each independent. All simulations have a sense of time - a unitless measure of time "step" will be used but it's up to you how it is interpreted (step is a non-negative integer, implemented using `size_t`).

### Model code

To implement this model in dust we write out a C++ file that looks like:

```{r walk_code, echo = FALSE, results = "asis"}
cc_output(readLines(dust:::dust_file("examples/walk.cpp")))
```

There are two main parts here; the class (`walk`) and an interface function (`dust::dust_pars`).

The class is what does most of the work. It is important that this does not use anything in the R api as it may be called in parallel. Therefore use only C++ standard library types.  It has to provide every public type or method as the example above:

* the type `real_t` has to exist and indicate what sort of numeric type you use for "real numbers". Typically this will be `double`,but if you need a different type (longer or shorter) you can use it here.
* the type `data_t` which for now should match exactly the construction `typedef dust::no_data data_t` until we stabilise and document this interface
* the type `shared_type` is whatever data your model needs that is shared across a number of particles, and unmodified during the model update (most likely parameters), and an object of this type will be passed to your constructor as the `.shared` field to `pars` (see `dust::dust_pars` below, and see `vignette("multi")` for more on parameters)
* the type `internal_type` is whatever internal data your model needs (most likely scratch space used for intermediate calculations), and an object of this type will be passed to your constructor as the `.internal` field to `pars` (see `dust::dust_pars` below)
* the type `rng_state_type` is one of the valid RNG types. For now leave this as `dust::random::xoshiro256starstar_state`
* the constructor must take only one argument, being `const dust::dust_pars<model>&`. You can do what you want in the constructor - here we just copy `shared` (containing parameters) into the object with the `pars` argument (we use the private member `shared` here but this can be anything you want, though the type is important)
* the method `size()` must return the "size" of the system - how many state variables it has. Here we're considering a single individual moving randomly so the size is always 1
* the method `initial()` returns the initial state of the model system. It must have length `size()` and it can vary based on the "step" of the system
* the method `update()` is the core of the system and specifies how the state changes from one step to another. It will always have the signature as above with arguments `size_t step` (the current step), `const double * state` (a read-only copy of the state when entering this step), `rng_state_type& rng` (a reference to the random number state) and `double * state_next` (a reference to the state to be updated). Your method reads from `state` and writes to `state_next`. Here, we unpack the mean and draw a new normally distributed random number - note how the standard deviation is retrieved from the `pars_` object.

The function below the class is a template specialisation of a dust function `dust_pars`; it is used to create your `dust::pars_type<model>` object from an R list (`cpp11::list`). You can include `cpp11.hpp` (or more narrowly scoped cpp11 headers) at this point and can use any cpp11 function that you need. Avoid direct use of the R's C API as this is not always safe to call from C++. In particular, use `cpp11::stop()` rather than `Rf_error()`.

Here we retrieve the `sd` element of the list and convert it to a "real number" type. This roughly equivalent to writing

```r
sd <- as.numeric(pars[["sd"]])
```

in R, except that it will throw an error if `sd` is not present in the list `pars`.  Then we construct the struct and return it.

### Constructing a model

The function `dust::dust` will "compile" a model for us to use:

```{r walk_compile, eval = FALSE}
path_walk <- system.file("examples/walk.cpp", package = "dust")
walk <- dust::dust(path_walk, quiet = TRUE)
```

However, this is also bundled into the package and can be loaded with:

```{r walk_load}
walk <- dust::dust_example("walk")
```

The object itself is an "R6ClassGenerator" object:

```{r walk_object}
walk
```

Create an instance of the model using `walk$new`. There are three required arguments:

* `pars`: passed to `dust_pars` to initialise the model
* `step`: the initial step (0 seems like a sensible choice here given our model has no internal sense of time)
* `n_particles`: the number of particles to create

```{r walk_create}
model <- walk$new(list(sd = 1), 0, 20)
model
```

This returns an R6 object that can be used to simulate from or interact with the model.  For example, our initial model state is

```{r walk_initial_state}
model$state()
```

and we can run the model for 100 steps, which returns the state at the end of the walk (and not at any intermediate steps):

```{r walk_run_1}
model$run(100)
```

We can also directly retrieve the state from our object

```{r walk_state_1}
model$state()
```

At this point our particles have been run for 100 steps with standard deviation 1 at each step so they [will be distributed following Normal(0, 10)](https://en.wikipedia.org/wiki/Random_walk#Gaussian_random_walk).  This is easier to see if we simulate a lot of particles:

```{r walk_simulate_many}
model <- walk$new(list(sd = 1), 0, 20000)
invisible(model$run(100))
hist(model$state(), freq = FALSE, las = 1, col = "steelblue2", main = "",
     ylim = c(0., 0.04), xlab = "State")
curve(dnorm(x, 0, 10), col = "orange", add = TRUE, lwd = 2)
```

### Running a model in parallel

The approach above still runs everything in serial, one particle after another. We can configure this system to run in parallel by providing the extra argument `n_threads` to the constructor.

Provided that your system can compile with openmp the following code will execute in parallel using 2 threads

```{r, walk_parallel}
model <- walk$new(list(sd = 1), 0, 20, n_threads = 2)
model$run(100)
```

Running this same code in series will give the same results:

```{r, walk_serial}
model <- walk$new(list(sd = 1), 0, 20, n_threads = 1)
model$run(100)
```

We use as many random number generators as there are particles, so if you run fewer particles or more, increase the threads or decrease, the results will be the same (see `vignette("design")` for more on this).

## A more interesting example

Consider now an SIR model (Susceptible - Infected - Recovered). This sort of model is common in epidemiology, and is often extended to add additional compartments (e.g., SEIR which adds an Exposed compartment) or by structuring each compartment based on properties such as age.  Here, we show a simple example with just 3 compartments:

```{r sir_code, echo = FALSE, results = "asis"}
cc_output(readLines(dust:::dust_file("examples/sir.cpp")))
```

There a few changes here compared to the version that was shown before for the walk model, but the core parts are only slightly different:

* the `initial` method is slightly more complicated as we initialise a 3-element vector
* our `shared_type` object has significantly more elements
* the `dust_pars` function is much more complicated
* there is a `compare_data` method and a nontrivial `data_t` definition, but ignore these for now

The other difference is a new template specialisation of `dust_info` - this is optional but can be used to report back to R information about the model based on the input parameters. Here it returns information about variable order and core parameters.

We also have added C++ pseudo-attributes with `[[dust::param]]` to describe the parameters that this function takes. This is optional, but allows use of a `coef` method with the class (see below).

As before, we'll use the version bundled with the package

```{r sir_compile}
sir <- dust::dust_example("sir")
```

To get information about the parameters, use `coef()` on the generator

```{r sir_coef}
coef(sir)
```

The model is initialised the same way as before:

```{r sir_create}
model <- sir$new(list(), 0, 20)
```

We can use the `$info()` method to retrieve information about our model:

```{r sir_info}
model$info()
```

and get its state as before:

```{r sir_initial_state}
model$state()
```

Suppose that as we run the model we mostly want information on the "I" compartment. So we'll run the model for a bit and retrieve the number of infected individuals, then continue, etc.  To do this we use the `$set_index()` method to indicate which state elements should be returned after using `$run()`:

```{r sir_set_index}
model$set_index(2L)
```

(you can pass any integer vector here, of any length, provided all the indices lie between 1 and the length of your state vector)

Now, when using `run`, the number of infected individuals is returned

```{r sir_run}
model$run(10)
model$run(20)
```

This is useful when you have many compartments or variables that you are not that interested in during running the model. For a particle filter you might be fitting to the sum of all infected individuals over a number of compartments, so rather than returning hundreds of values back (times hundreds of particles) you can return back much less data and keep things nice and fast.

If the index vector is named, then those names will be used as row names on the returned object:

```{r sir_run_named}
model$set_index(c(I = 2L))
model$run(30)
```

We can always use `$state()` to get the whole state vector:

```{r sir_state}
model$state()
```

or select only variables of interest:

```{r sir_state_select}
model$state(c(S = 1L, R = 3L))
```

Again, this copies names from the index if they are present.

In order to run the simulation beginning-to-end, we use the `$simulate` method on a dust object, which runs over a set of steps and records the state at each.

```{r sir_run_collect}
model <- sir$new(list(), 0, 200)
model$set_index(2L)
steps <- seq(0, 600, by = 5)
state <- model$simulate(steps)
```

The output here is a 1 x 200 x 121 matrix (n state x n particles x n steps)

```{r sir_run_dim}
dim(state)
```

we need to drop the first dimension and transpose the others for ease of plotting:

```{r sir_transform}
traces <- t(drop(state))
```

Plotting this over time (with 4 steps per day - see the sir code above)

```{r sir_average}
time <- steps / 4
matplot(time, traces, type = "l", lty = 1, col = "#00000022",
        xlab = "Time", ylab = "Number infected (I)")
lines(time, rowMeans(traces), col = "red", lwd = 2)
```

## Other methods

There are a few other methods on the walk objects that may be useful.

### Reordering particles

This method exists to support particle filtering, and allows resampling or reordering of particles.

```{r reorder_setup}
model <- walk$new(list(sd = 1), 0, 20)
model$run(1)
```

Suppose that we wanted to reorder these particles so that they were in decreasing order:

```{r reorder_index}
index <- order(model$state())
index
```

We then pass this `index` to the reorder method:

```{r reorder_apply}
model$reorder(index)
model$state()
```

We can then continue our random walk. There is no need to sample every particle and particles can appear multiple times in the sample, but the total number must be conserved.  Suppose that we want to to sample particles based on how close they are to 0:

```{r reorder_weighted_index}
p <- dnorm(model$state())
index <- sample(length(p), replace = TRUE , prob = p)
index
```

We can then apply this sampling:

```{r reorder_weighted_apply}
model$reorder(index)
model$state()
```

This is not terribly useful on its own but is a key part of a particle filter.

### Set initial state

By default every particle starts from the initial condition specified by your model classes `initial()` method. However, you can specify a state directly using the `$update_state()` method. Here, we initialise our SIR model with only 1 infected individual rather than 10:

```{r update_state}
model <- sir$new(list(), 0, 20)
model$update_state(state = c(1000, 1, 0, 0, 0))
model$state()
```

Now, when we run the model, far more of the epidemics fail to take off as the infected individual goes disappears before infecting anyone.

```{r}
steps <- seq(0, 600, by = 5)
state <- model$simulate(steps)
time <- steps / 4
matplot(time, t(state[2, , ]), type = "l", lty = 1, col = "#00000022",
        xlab = "Time", ylab = "Number infected (I)")
```

You can optionally set the initial step at the same time as the state. This is useful in two cases; if your model depends on time (e.g., you use the step in a calculation by transforming it into some measure of time) or if your particles start at different points. For example, suppose we start 10 individuals in the infected state but we do so with a number of possible starting points sampled from between step 0 and step 30:

```{r initial_step}
step0 <- sample(0:30, 20, replace = TRUE)
model <- sir$new(list(), 0, 20)
model$update_state(state = c(1000, 10, 0, 0, 0), step = step0)
```

After initialisation, our model is now at `r max(step0)`, the last step referenced in `step0`

```{r}
model$step()
```

and the initial states are a mix of states, despite having been seeded with the same 10 infected individuals, as different particles have run for different numbers of steps to reach this common time point:

```{r}
model$state()
```

From this point we can continue to run the simulation as before:

```{r}
steps <- seq(max(step0), 600, by = 5)
state <- model$simulate(steps)
time <- steps / 4
matplot(time, t(state[2, , ]), type = "l", lty = 1, col = "#00000022",
        xlab = "Time", ylab = "Number infected (I)")
```

You can also set the initial state to a range of different values. Suppose we set the initial number of infections to be Poisson distributed with a mean of 10, we might write:

```{r}
I0 <- rpois(20, 10)
state0 <- rbind(1010 - I0, I0, 0, 0, 0, deparse.level = 0)
model$update_state(state = state0, step = 0L)
model$step()
model$state()
```

Here, we have our variable initial state and all particles starting at step 0. You can combine the two approaches to have a variable initial state and variable initial time by running

```{r}
model$update_state(state = state0, step = step0)
model$step()
model$state()
```

### Reset the model

After running model once, we need to "reset" it to run again. You should not create a new model as that will re-seed a new set of random state, but continue with the state in your old model.

Suppose we run our model with sd of 1 for 200 steps

```{r}
model <- walk$new(list(sd = 1), 0, 200, seed = 1L)
y1 <- model$run(100)
```

we then use `reset` to set new parameters into the model and set the time back to zero and can run again

```{r}
model <- walk$new(list(sd = 2), 0, 200)
y2 <- model$run(100)
```

## Use within a package

You should not use `dust::dust()` within a package, because that would cause the model to compile each time you use it, rather than when the package builds. Instead you should use `dust::dust_package()` which will generate appropriate code for you.

To use dust in a package, put your dust models in `inst/dust` and run `dust::dust_package()` on the package's root directory.

```{r pkg_setup, include = FALSE}
desc <- c(
  "Package: example",
  "Title: Example Dust in a Package",
  "Version: 0.0.1",
  "LinkingTo: cpp11, dust",
  "Authors@R: c(person('A', 'Person', role = c('aut', 'cre')",
  "                     email = 'person@example.com'))",
  "SystemRequirements: C++11",
  "License: CC0")
ns <- "useDynLib('example', .registration = TRUE)"

path <- tempfile()
dir.create(path)
dir.create(file.path(path, "inst/dust"), FALSE, TRUE)
writeLines(desc, file.path(path, "DESCRIPTION"))
writeLines(ns, file.path(path, "NAMESPACE"))
path_ex <- system.file("examples", package = "dust", mustWork = TRUE)
file.copy(file.path(path_ex, "walk.cpp"), file.path(path, "inst/dust"))
```

A skeleton package might contain:

```{r pkg_tree, echo = FALSE}
withr::with_dir(path, fs::dir_tree())
```

This is the normal R package skeleton, though missing R and src directories (for now).  The DESCRIPTION file contains

```{r pkg_desc, echo = FALSE, results = "asis"}
plain_output(readLines(file.path(path, "DESCRIPTION")))
```

The important things here are:

* the package name (`Package`). We're using `example`, and names with a dot may not work as expected
* including [`cpp11`](https://github.com/r-lib/cpp11) and `dust` in `LinkingTo`, which allows package compilation to find their respective header files
* a `useDynLib` call to your package in the `NAMESPACE` file

The files in `inst/dust` are the same files as seen above, with `walk.cpp` containing

```{r pkg_walk, echo = FALSE, results = "asis"}
cc_output(readLines(file.path(path, "inst/dust/walk.cpp")))
```

There can be as many of these files as you want.

To prepare the package, run `dust::dust_package()`:

```{r pkg_generate}
dust::dust_package(path)
```

The directory structure now has more files:

```{r pkg_tree_after, echo = FALSE}
withr::with_dir(path, fs::dir_tree())
```

The file `src/walk.cpp` are generated by dust and should not be edited. They include your model, but also a bit of helper code:

```{r pkg_walk_c, echo = FALSE, results = "asis"}
cc_output(readLines(file.path(path, "src/walk.cpp")))
```

The file `R/dust.R` contains the R interface generated by dust with the constructor objects (all models' constructors will be collected into this file, which also should not be edited).

```{r pkg_dust_r, echo = FALSE, results = "asis"}
r_output(readLines(file.path(path, "R/dust.R")))
```

Finally, `R/cpp11.R` and `src/cpp11.cpp` are files created by cpp11 that should not be edited.

Your package can include as much R code as you want, and can be developed like any other R package. But any time you change the code in `inst/dust` you should rerun `dust::dust_package()`.
